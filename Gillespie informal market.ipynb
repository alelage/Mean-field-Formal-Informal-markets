{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#######################################################################\n",
      "#                                                                     #\n",
      "#            Welcome to the interactive StochPy environment           #\n",
      "#                                                                     #\n",
      "#######################################################################\n",
      "#  StochPy: Stochastic modeling in Python                             #\n",
      "#  http://stochpy.sourceforge.net                                     #\n",
      "#  Copyright(C) T.R Maarleveld, B.G. Olivier, F.J Bruggeman 2010-2015 #\n",
      "#  DOI: 10.1371/journal.pone.0079345                                  #\n",
      "#  Email: tmd200@users.sourceforge.net                                #\n",
      "#  VU University, Amsterdam, Netherlands                              #\n",
      "#  Centrum Wiskunde Informatica, Amsterdam, Netherlands               #\n",
      "#  StochPy is distributed under the BSD licence.                      #\n",
      "#######################################################################\n",
      "\n",
      "Version 2.4.0\n",
      "Output Directory: C:\\Stochpy\n",
      "Model Directory: C:\\Stochpy\\pscmodels\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import stochpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 100\n",
    "ref_price_a = ref_price_b = 100\n",
    "std_price_a = std_price_b = 1\n",
    "\n",
    "price_bins = np.linspace(\n",
    "    min(ref_price_a, ref_price_b) - 5 * std_price_b,\n",
    "    max(ref_price_a, ref_price_b) + 5 * std_price_a,\n",
    "    300\n",
    ")\n",
    "\n",
    "# Midpoints and bin width\n",
    "midpoints = (price_bins[:-1] + price_bins[1:]) / 2\n",
    "dp = midpoints[1] - midpoints[0]\n",
    "num_bins = len(midpoints)  # Number of bins\n",
    "\n",
    "prices_A = midpoints.copy()\n",
    "prices_B = midpoints.copy()  # Same bins for B\n",
    "\n",
    "# Parámetros de simulación\n",
    "phi = 15 * dp\n",
    "delta = 0.01\n",
    "kappa = 0.01\n",
    "beta = 0\n",
    "\n",
    "species_A = [f\"A{i+1}\" for i in range(num_bins)]\n",
    "species_B = [f\"B{i+1}\" for i in range(num_bins)]\n",
    "\n",
    "all_species = species_A + species_B\n",
    "\n",
    "def gaussian(x):\n",
    "    return (1/(std_price_a * np.sqrt(2 * np.pi))) * np.exp(- (x - mu)**2 / (2 * std_price_a**2))\n",
    "\n",
    "gaussian_values = [gaussian(p) for p in prices_A]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial conditions\n",
    "def get_initial_counts(n_particles):\n",
    "    counts = [0] * num_bins\n",
    "    for _ in range(n_particles):\n",
    "        x = np.random.normal(mu, std_price_a)\n",
    "        if (ref_price_b - 5 * std_price_b)  <= x <= (ref_price_a + 5 * std_price_a):\n",
    "            bin_idx = int((x - (ref_price_b - 5 * std_price_b)) / dp)\n",
    "            if bin_idx >= num_bins:\n",
    "                bin_idx = num_bins - 1\n",
    "            counts[bin_idx] += 1\n",
    "    return counts\n",
    "\n",
    "initial_A = get_initial_counts(100)\n",
    "initial_B = get_initial_counts(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "creation_reactions = []\n",
    "for i in range(num_bins):\n",
    "    # Reacciones de creación para A\n",
    "    rate_A = phi * gaussian_values[i]\n",
    "    rate_A_str = \"{:.10f}\".format(rate_A)\n",
    "    creation_reactions.append(\n",
    "        f\"creation_{species_A[i]}:\\n\"\n",
    "        f\"    $pool > {species_A[i]}\\n\"\n",
    "        f\"    {rate_A_str}\"\n",
    "    )\n",
    "    # Reacciones de creación para B\n",
    "    rate_B = phi * gaussian_values[i]\n",
    "    rate_B_str = \"{:.10f}\".format(rate_B)\n",
    "    creation_reactions.append(\n",
    "        f\"creation_{species_B[i]}:\\n\"\n",
    "        f\"    $pool > {species_B[i]}\\n\"\n",
    "        f\"    {rate_B_str}\"\n",
    "    )\n",
    "\n",
    "death_reactions = []\n",
    "for i in range(num_bins):\n",
    "    death_reactions.append(\n",
    "        f\"death_{species_A[i]}:\\n\"\n",
    "        f\"    {species_A[i]} > $pool\\n\"\n",
    "        f\"    delta * {species_A[i]}\"\n",
    "    )\n",
    "    death_reactions.append(\n",
    "        f\"death_{species_B[i]}:\\n\"\n",
    "        f\"    {species_B[i]} > $pool\\n\"\n",
    "        f\"    delta * {species_B[i]}\"\n",
    "    )\n",
    "\n",
    "interaction_reactions = []\n",
    "for A_idx in range(num_bins):\n",
    "    for B_idx in range(A_idx + 1, num_bins):\n",
    "        A_species = species_A[A_idx]\n",
    "        B_species = species_B[B_idx]\n",
    "        if prices_B[B_idx] >= prices_A[A_idx]:\n",
    "            price_diff = prices_B[B_idx] - prices_A[A_idx]\n",
    "            rate = np.exp(beta * price_diff) * kappa\n",
    "            rate_str = f\"{rate:.10f}\"\n",
    "            reaction = (\n",
    "                f\"interaction_{A_species}_{B_species}:\\n\"\n",
    "                f\"    {A_species} + {B_species} > $pool\\n\"\n",
    "                f\"    {rate_str} * {A_species} * {B_species}\"\n",
    "            )\n",
    "            interaction_reactions.append(reaction)\n",
    "\n",
    "all_reactions = creation_reactions + death_reactions + interaction_reactions\n",
    "\n",
    "# Escribir modelo\n",
    "model_filename = \"Gillespie_mercado_informal_final.psc\"\n",
    "full_model_path = \"C:\\\\Stochpy\\\\pscmodels\\\\Gillespie_mercado_informal_final.psc\"\n",
    "\n",
    "with open(full_model_path, 'w') as f:\n",
    "    # Condiciones iniciales\n",
    "    f.write(\"#InitVar:\\n\")\n",
    "    for i in range(num_bins):\n",
    "        f.write(f\"{species_A[i]} = {initial_A[i]}\\n\")\n",
    "    for i in range(num_bins):\n",
    "        f.write(f\"{species_B[i]} = {initial_B[i]}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    # Parámetros\n",
    "    f.write(\"#InitPar:\\n\")\n",
    "    f.write(f\"delta = {delta}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    # Reacciones\n",
    "    f.write(\"#Reactions:\\n\")\n",
    "    for reaction in all_reactions:\n",
    "        f.write(reaction + \"\\n\\n\")\n",
    "\n",
    "model = stochpy.SSA()\n",
    "model.Model(full_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    }
   ],
   "source": [
    "desired_order =  species_A + species_B\n",
    "num_sims = 5\n",
    "model.Endtime(1000)\n",
    "model.DoStochSim(\n",
    "    trajectories = num_sims,\n",
    "    species_selection=desired_order \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_a_sim_array = []\n",
    "total_b_sim_array = []\n",
    "stationary_a_sim_array = []\n",
    "stationary_b_sim_array = []\n",
    "\n",
    "for i in range(num_sims):\n",
    "\n",
    "    model.GetTrajectoryData(i+1)\n",
    "\n",
    "    total_timepoints = len(model.data_stochsim.time)\n",
    "\n",
    "    percent = 0.5\n",
    "    last_percent = int(percent * total_timepoints)\n",
    "    start_idx = max(0, total_timepoints - last_percent)\n",
    "\n",
    "    counts_A = model.data_stochsim.species[:,:num_bins]\n",
    "    counts_B = model.data_stochsim.species[:,num_bins:]\n",
    "\n",
    "    final_A_counts = np.mean(counts_A[start_idx:, :], axis=0) / dp\n",
    "    final_B_counts = np.mean(counts_B[start_idx:, :], axis=0) / dp\n",
    "\n",
    "    total_particles_A = []\n",
    "    total_particles_B = [] \n",
    "\n",
    "    times = model.data_stochsim.time\n",
    "\n",
    "    for t in range(total_timepoints):\n",
    "\n",
    "        counts_Ai = counts_A[t]\n",
    "        counts_Bi = counts_B[t]\n",
    "\n",
    "        total_particles_A.append(np.sum(counts_Ai)) \n",
    "        total_particles_B.append(np.sum(counts_Bi))\n",
    "\n",
    "    total_particles_A = np.column_stack((total_particles_A,times))\n",
    "    total_particles_B = np.column_stack((total_particles_B,times))\n",
    "        \n",
    "    total_a_sim_array.append(total_particles_A)\n",
    "    total_b_sim_array.append(total_particles_B)\n",
    "    stationary_a_sim_array.append(final_A_counts)\n",
    "    stationary_b_sim_array.append(final_B_counts)\n",
    "\n",
    "dt = 1 \n",
    "common_time = np.arange(0, 1000 + dt, dt)\n",
    "\n",
    "def interpolate_series(times, values, common_time):\n",
    "\n",
    "    times, idx = np.unique(times, return_index=True)\n",
    "    values = values[idx]\n",
    "    interp_func = interp1d(times, values, kind='linear', fill_value='extrapolate')\n",
    "\n",
    "    return interp_func(common_time)\n",
    "\n",
    "all_interpolated_a = [] \n",
    "\n",
    "for sim_data in total_a_sim_array:\n",
    "    times = sim_data[:,1]\n",
    "    values = sim_data[:,0]\n",
    "    interpolated = interpolate_series(times, values, common_time)\n",
    "    all_interpolated_a.append(interpolated)\n",
    "\n",
    "all_interpolated_a = np.array(all_interpolated_a)\n",
    "total_a_sim_array = np.mean(all_interpolated_a, axis=0)\n",
    "\n",
    "all_interpolated_b = []  \n",
    "\n",
    "for sim_data in total_b_sim_array:\n",
    "    times = sim_data[:,1]\n",
    "    values = sim_data[:,0]\n",
    "    interpolated = interpolate_series(times, values, common_time)\n",
    "    all_interpolated_b.append(interpolated)\n",
    "\n",
    "all_interpolated_b = np.array(all_interpolated_b)\n",
    "total_b_sim_array = np.mean(all_interpolated_b, axis=0)\n",
    "\n",
    "mean_stationary_a_sim_array = np.mean(np.array(stationary_a_sim_array), axis = 0)\n",
    "mean_stationary_b_sim_array = np.mean(np.array(stationary_b_sim_array), axis = 0)\n",
    "\n",
    "std_total_a_sim_array = np.std(all_interpolated_a, axis=0) / np.sqrt(num_sims)\n",
    "upper_bound_total_a_sim_array = total_a_sim_array + std_total_a_sim_array\n",
    "lower_bound_total_a_sim_array = total_a_sim_array - std_total_a_sim_array\n",
    "\n",
    "std_total_b_sim_array = np.std(all_interpolated_b, axis=0) / np.sqrt(num_sims)\n",
    "upper_bound_total_b_sim_array = total_b_sim_array + std_total_b_sim_array\n",
    "lower_bound_total_b_sim_array = total_b_sim_array - std_total_b_sim_array\n",
    "\n",
    "std_stationary_a_sim_array = np.std(stationary_a_sim_array, axis=0) / np.sqrt(num_sims)\n",
    "upper_mean_stationary_a_sim_array = mean_stationary_a_sim_array + std_stationary_a_sim_array\n",
    "lower_mean_stationary_a_sim_array = mean_stationary_a_sim_array - std_stationary_a_sim_array\n",
    "\n",
    "std_stationary_b_sim_array = np.std(stationary_b_sim_array, axis=0) / np.sqrt(num_sims)\n",
    "upper_mean_stationary_b_sim_array = mean_stationary_b_sim_array + std_stationary_b_sim_array\n",
    "lower_mean_stationary_b_sim_array = mean_stationary_b_sim_array - std_stationary_b_sim_array\n",
    "\n",
    "with open(\"resources\\\\Gillespie mercado informal\\\\n_A_totales_gillespie.pkl\", 'wb') as f:\n",
    "    pickle.dump(total_a_sim_array,f)\n",
    "with open(\"resources\\\\Gillespie mercado informal\\\\n_B_totales_gillespie.pkl\", 'wb') as f:\n",
    "    pickle.dump(total_b_sim_array,f)\n",
    "with open(\"resources\\\\Gillespie mercado informal\\\\times_gillespie.pkl\", 'wb') as f:\n",
    "    pickle.dump(common_time,f)\n",
    "with open(\"resources\\\\Gillespie mercado informal\\\\n_A_estacionario_gillespie.pkl\", 'wb') as f:\n",
    "    pickle.dump(mean_stationary_a_sim_array,f)\n",
    "with open(\"resources\\\\Gillespie mercado informal\\\\n_B_estacionario_gillespie.pkl\", 'wb') as f:\n",
    "    pickle.dump(mean_stationary_b_sim_array,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"resources\\\\Gillespie mercado informal\\\\n_A.pkl\", 'wb') as f:\n",
    "    pickle.dump(total_particles_A,f)\n",
    "with open(\"resources\\\\Gillespie mercado informal\\\\n_B.pkl\", 'wb') as f:\n",
    "    pickle.dump(total_particles_B,f)\n",
    "with open(\"resources\\\\Gillespie mercado informal\\\\times.pkl\", 'wb') as f:\n",
    "    pickle.dump(times,f)\n",
    "with open(\"resources\\\\Gillespie mercado informal\\\\n_A_estacionario.pkl\", 'wb') as f:\n",
    "    pickle.dump(final_A_counts,f)\n",
    "with open(\"resources\\\\Gillespie mercado informal\\\\n_B_estacionario.pkl\", 'wb') as f:\n",
    "    pickle.dump(final_B_counts,f)\n",
    "with open(\"resources\\\\Gillespie mercado informal\\\\initial_A.pkl\", 'wb') as f:\n",
    "    pickle.dump(initial_A,f)\n",
    "with open(\"resources\\\\Gillespie mercado informal\\\\initial_B.pkl\", 'wb') as f:\n",
    "    pickle.dump(initial_B,f)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
