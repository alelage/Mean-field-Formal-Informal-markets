{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_steps = 10000\n",
    "dt = 0.1\n",
    "ref_price_a, ref_price_b = 100, 100\n",
    "lambda_a, lambda_b = 1.0, 1.0\n",
    "std_price_a, std_price_b = 1.0, 1.0\n",
    "delta_a, delta_b = dt * 0.01, dt * 0.01\n",
    "phi_a, phi_b = dt * 15, dt * 15\n",
    "kappa = dt * 0.01\n",
    "initial_particles_a = 100\n",
    "initial_particles_b = 100\n",
    "n_histograms = 5000\n",
    "\n",
    "# Initialize particles\n",
    "prices_a = np.random.normal(loc=ref_price_a, scale=std_price_a, size=initial_particles_a)\n",
    "sizes_a = np.random.exponential(scale=1 / lambda_a, size=initial_particles_a)\n",
    "prices_b = np.random.normal(loc=ref_price_b, scale=std_price_b, size=initial_particles_b)\n",
    "sizes_b = np.random.exponential(scale=1 / lambda_b, size=initial_particles_b)\n",
    "\n",
    "particles_a = np.column_stack((prices_a, sizes_a))\n",
    "particles_b = np.column_stack((prices_b, sizes_b))\n",
    "\n",
    "starting_distribution_a = particles_a.copy()\n",
    "starting_distribution_b = particles_b.copy()\n",
    "\n",
    "price_bins = np.linspace(\n",
    "    min(ref_price_a, ref_price_b) - 5 * std_price_b,\n",
    "    max(ref_price_a, ref_price_b) + 5 * std_price_a,\n",
    "    500\n",
    ")\n",
    "\n",
    "dp = price_bins[1]-price_bins[0]\n",
    "\n",
    "# Arrays to store statistics\n",
    "time_steps = []\n",
    "n_a_array = []\n",
    "n_b_array = []\n",
    "mean_price_a_array = []\n",
    "mean_price_b_array = []\n",
    "std_price_a_array = []\n",
    "std_price_b_array = []\n",
    "\n",
    "# To store histograms of the last n steps\n",
    "last_histograms_a = []\n",
    "last_histograms_b = []\n",
    "\n",
    "# Processes\n",
    "def add_entries():\n",
    "    global particles_a, particles_b\n",
    "\n",
    "    n_new_a = np.random.poisson(phi_a)\n",
    "    n_new_b = np.random.poisson(phi_b)\n",
    "\n",
    "    if n_new_a > 0:\n",
    "        new_prices_a = np.random.normal(loc=ref_price_a, scale=std_price_a, size=n_new_a)\n",
    "        new_sizes_a = np.random.exponential(scale=1 / lambda_a, size=n_new_a)\n",
    "        particles_a = np.vstack((particles_a, np.column_stack((new_prices_a, new_sizes_a))))\n",
    "\n",
    "    if n_new_b > 0:\n",
    "        new_prices_b = np.random.normal(loc=ref_price_b, scale=std_price_b, size=n_new_b)\n",
    "        new_sizes_b = np.random.exponential(scale=1 / lambda_b, size=n_new_b)\n",
    "        particles_b = np.vstack((particles_b, np.column_stack((new_prices_b, new_sizes_b))))\n",
    "\n",
    "def perform_interactions():\n",
    "    global particles_a, particles_b\n",
    "\n",
    "    def process_interactions(particles_x, particles_y, kappa):\n",
    "\n",
    "        interactions_rate = kappa * len(particles_y)\n",
    "\n",
    "        for i in range(len(particles_x)):\n",
    "            n_interactions = np.random.poisson(interactions_rate)\n",
    "\n",
    "            if len(particles_y) == 0:\n",
    "                break\n",
    "            if n_interactions > 0:\n",
    "                chosen_indices = np.random.choice(len(particles_y), size=min(n_interactions, len(particles_y)), replace=False)\n",
    "\n",
    "                for idx in chosen_indices:\n",
    "                    price_x, size_x = particles_x[i]\n",
    "                    price_y, size_y = particles_y[idx]\n",
    "\n",
    "                    # Uncomment for volumes\n",
    "\n",
    "                    # if price_y >= price_x:\n",
    "                    #     if size_x < size_y:\n",
    "                    #         particles_y[idx, 1] -= size_x\n",
    "                    #         particles_x[i] = [0, 0]  # Marked for deletion\n",
    "                    #         break\n",
    "                    #     if size_x > size_y:\n",
    "                    #         particles_x[i, 1] -= size_y\n",
    "\n",
    "                    #         if particles_x[i, 1] < 0:\n",
    "                    #             print('Negative volume')\n",
    "\n",
    "                    #         particles_y[idx] = [0, 0]  # Marked for deletion\n",
    "\n",
    "\n",
    "                    # Uncomment for no volumes        \n",
    "\n",
    "                    if price_y >= price_x:\n",
    "                        particles_x[i] = [0, 0]  # Marked for deletion\n",
    "                        particles_y[idx] = [0, 0]  # Marked for deletion\n",
    "                        break\n",
    "\n",
    "            particles_y = particles_y[np.any(particles_y != [0, 0], axis=1)]\n",
    "        particles_x = particles_x[np.any(particles_x != [0, 0], axis=1)]\n",
    "        \n",
    "        return particles_x, particles_y\n",
    "\n",
    "    particles_a, particles_b = process_interactions(particles_a, particles_b, kappa)\n",
    "    \n",
    "def apply_cancellations():\n",
    "    global particles_a, particles_b\n",
    "    particles_a = particles_a[np.random.rand(len(particles_a)) > delta_a]\n",
    "    particles_b = particles_b[np.random.rand(len(particles_b)) > delta_b]\n",
    "\n",
    "def record_totals(step):\n",
    "    global particles_a, particles_b, time_steps\n",
    "\n",
    "    time_steps.append(step)\n",
    "    n_a_array.append(len(particles_a))\n",
    "    n_b_array.append(len(particles_b))\n",
    "\n",
    "def record_histograms(n_histograms = n_histograms):\n",
    "    global last_histograms_a, last_histograms_b\n",
    "    \n",
    "    hist_a, _ = np.histogram(particles_a[:, 0], bins=price_bins)\n",
    "    hist_b, _ = np.histogram(particles_b[:, 0], bins=price_bins)\n",
    "    \n",
    "    last_histograms_a.append(hist_a)\n",
    "    last_histograms_b.append(hist_b)\n",
    "\n",
    "    if len(last_histograms_a) > n_histograms:\n",
    "        last_histograms_a.pop(0)\n",
    "    if len(last_histograms_b) > n_histograms:\n",
    "        last_histograms_b.pop(0)\n",
    "\n",
    "def one_step(step):\n",
    "    record_totals(step)\n",
    "    add_entries()\n",
    "    perform_interactions()\n",
    "    apply_cancellations()\n",
    "    \n",
    "    if step >= n_steps - n_histograms:\n",
    "        record_histograms()\n",
    "\n",
    "# Run simulation\n",
    "for step in range(n_steps):\n",
    "    one_step(step)\n",
    "    if len(particles_a) == 0 and len(particles_b) == 0:\n",
    "        print(f\"Simulation ended at step {step}.\")\n",
    "        break\n",
    "\n",
    "# Average histograms\n",
    "final_counts_a = np.mean(last_histograms_a/dp, axis=0)\n",
    "final_counts_b = np.mean(last_histograms_b/dp, axis=0)\n",
    "\n",
    "initial_counts_a, _ = np.histogram(starting_distribution_a[:, 0], bins=price_bins)\n",
    "initial_counts_b, _ = np.histogram(starting_distribution_b[:, 0], bins=price_bins)\n",
    "xvalues = [(price_bins[i] + price_bins[i+1])/2 for i in range(len(price_bins) -1 )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"resources\\\\Simulacion mercado informal\\\\totales_n_a_10.pkl\", 'wb') as f:\n",
    "    pickle.dump(n_a_array,f)\n",
    "with open(\"resources\\\\Simulacion mercado informal\\\\totales_n_b_10.pkl\", 'wb') as f:\n",
    "    pickle.dump(n_b_array,f)\n",
    "with open(\"resources\\\\Simulacion mercado informal\\\\times_10.pkl\", 'wb') as f:\n",
    "    pickle.dump(time_steps,f)\n",
    "with open(\"resources\\\\Simulacion mercado informal\\\\n_A_estacionario_10.pkl\", 'wb') as f:\n",
    "    pickle.dump(final_counts_a,f)\n",
    "with open(\"resources\\\\Simulacion mercado informal\\\\n_B_estacionario_10.pkl\", 'wb') as f:\n",
    "    pickle.dump(final_counts_b,f)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
